{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 General imports for all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# General imports for all experiments\n",
    "from lrdms.constants import DATA_PATH\n",
    "from lrdms.data.srired import IRED\n",
    "from lrdms.utils.mutations import Variant, count_possible_mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and pre-process the data\n",
    "srired = IRED()\n",
    "srired\n",
    "\n",
    "# Single mutant statistics\n",
    "_n_singles_observed = len(srired.data.query(\"hamming_to_wildtype == 1\"))\n",
    "_n_singles_possible = count_possible_mutations(srired.sequence_length, 1)\n",
    "print(\n",
    "    f\"Observed single mutants: {_n_singles_observed} / {_n_singles_possible} possible ({_n_singles_observed / _n_singles_possible:.2%})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load tranception & ESM prediction data for singles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `Tranception` language model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tranception data\n",
    "tranception_results = pd.read_csv(\n",
    "    DATA_PATH / \"srired_tranception_predictions_plm_only.csv\"\n",
    ")  # TODO: Rename & create code to generate this file\n",
    "tranception_results[\"variant\"] = tranception_results.mutated_sequence.apply(\n",
    "    lambda x: str(Variant.from_mutated_seq(x, srired.wildtype_seq))\n",
    ")\n",
    "\n",
    "# Map corresponding values based on `variant` to srired.data via a dataframe join\n",
    "srired.data = srired.data.merge(tranception_results[[\"variant\", \"avg_score\"]], on=\"variant\", how=\"left\")\n",
    "srired.data = srired.data.assign(avg_score=srired.data.avg_score.fillna(0))\n",
    "srired.data.rename(columns={\"avg_score\": \"tranception_log_density\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `ESM` language model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ESM data\n",
    "esm_singles = pd.read_csv(\n",
    "    DATA_PATH / \"srired_esm2_predictions_single_mutants.csv\", index_col=0\n",
    ")  # TODO: Rename & create code to generate this file\n",
    "esm_singles.rename(columns={\"fitness\": \"esm_log_density\"}, inplace=True)\n",
    "srired.data = srired.data.merge(esm_singles[[\"variant\", \"esm_log_density\"]], on=\"variant\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Set up singles predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrdms.data.predictions import VariantPredictions\n",
    "from lrdms.utils.mutations import generate_single_mutants\n",
    "\n",
    "# Set up singles data\n",
    "singles = VariantPredictions.from_variants(srired, generate_single_mutants(srired.wildtype_seq))\n",
    "singles.data[\"seq\"] = singles.data.variant.apply(lambda x: Variant.from_str(x).get_sequence(srired.wildtype_seq))\n",
    "\n",
    "# Match ESM singles predictions\n",
    "singles.data = singles.data.merge(\n",
    "    esm_singles.rename(columns=dict(esm_log_density=\"fitness_esm\")), left_on=\"variant\", right_on=\"variant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Singles evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrdms.model.single_mutations import JointPredictor, AAIndexPredictor, LookUpPredictor\n",
    "\n",
    "train, test = \"hamming_to_wildtype == 1\", \"hamming_to_wildtype == 1\"\n",
    "\n",
    "model = JointPredictor(\n",
    "    predictors=[\n",
    "        AAIndexPredictor(reg_coef=1.0, n_components=19, seed=7),\n",
    "        LookUpPredictor(singles.data.set_index(\"seq\")[\"fitness_esm\"].to_dict(), reg_coef=1e-6),\n",
    "    ],\n",
    "    reg_coef=1.0,\n",
    ")\n",
    "model.fit(\n",
    "    srired.data.query(train)[\"sequence\"].values,\n",
    "    srired.data.query(train)[\"fitness\"].values,\n",
    ")\n",
    "y_pred = model.predict(srired.data.query(test)[\"sequence\"].values)\n",
    "y_true = srired.data.query(test)[\"fitness\"].values\n",
    "\n",
    "singles.data[\"fitness_lr_combo\"] = model.predict(\n",
    "    singles.data.variant.apply(lambda x: Variant.from_str(x).get_sequence(singles.wildtype_seq))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final single-mutant predictions (top 10):\")\n",
    "singles.data.sort_values(by=\"fitness_lr_combo\", ascending=False).query(\"not observed\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Sensitivity against ESM dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AAIndexPredictor(reg_coef=1.0, n_components=19, seed=7)\n",
    "\n",
    "model.fit(\n",
    "    srired.data.query(train)[\"sequence\"].values,\n",
    "    srired.data.query(train)[\"fitness\"].values,\n",
    ")\n",
    "\n",
    "singles.data[\"pred_fitness_aaindex\"] = model.predict(\n",
    "    singles.data.variant.apply(lambda x: Variant.from_str(x).get_sequence(singles.wildtype_seq))\n",
    ")\n",
    "\n",
    "print(\"Final single-mutant predictions without using ESM (top 10):\")\n",
    "singles.data.sort_values(by=\"pred_fitness_aaindex\", ascending=False).query(\"not observed\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 ESM only predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the ESM log likelihood ratios performs for ranking single mutations on their own.\n",
    "\n",
    "The top 20 predicted mutants by ESM log likelihood ratio vs. wildtype are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singles.data.sort_values(by=\"fitness_esm\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single-mutants which turned out to be most fit in our experiments would have been ranked as follows by the ESM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singles.data.sort_values(by=\"fitness_esm\", ascending=False).reset_index().query(\"variant in ['T241G', 'T241A']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see:\n",
    "\n",
    "- `T241A`, the best performing variant from the experimental lrDMS data, would have been ranked `180/5510` and would require screening two 96-well plates to be selected for experimental validation.\n",
    "- `T241G`, the best performing single mutant of the model predictions (which outperforms the best experimental lrDMS) would have been \n",
    "ranked `457/5510`. This variant would have required screening five 96-well plates to be selected for experimental validation if we had used\n",
    "ESM predictions only.\n",
    "\n",
    "While `T241A` is ranked reasonably high, neither of the two best performing variants from the experimental data would have been selected with the experimental budget of 5 variants used in this study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrdms.eval.learning_curves import compute_learning_curves, WELL_PLATE_SIZES\n",
    "from lrdms.utils.common import named_partial\n",
    "from lrdms.eval.metrics import (\n",
    "    spearman,\n",
    "    hit_rate,\n",
    "    topk_mean,\n",
    "    topk_best_fitness,\n",
    "    topk_recall_from_quantile_q,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from plotstyle.export import save_timestamped_figure\n",
    "from plotstyle.colors import cambridge_core\n",
    "from plotstyle.size import get_dim, WIDTH\n",
    "\n",
    "CV = RepeatedStratifiedKFold(n_splits=3, n_repeats=10, random_state=7)\n",
    "METRICS = [\n",
    "    spearman,\n",
    "    named_partial(ndcg_at_k, k=10, name=\"top10_ndcg\"),\n",
    "    named_partial(ndcg_at_k, k=100, name=\"top100_ndcg\"),\n",
    "    named_partial(precision_at_k, k=10, name=\"top10_precision\"),\n",
    "    named_partial(topk_mean, topk=10, name=\"top10_mean\"),\n",
    "    named_partial(hit_rate, topk=10, name=\"top10_hit_rate\"),\n",
    "    named_partial(topk_recall_from_quantile_q, q=0.9, k=10, name=\"top10_recall_from_90th_percentile\"),\n",
    "    named_partial(topk_best_fitness, k=5, name=\"top5_best_fitness\"),\n",
    "    named_partial(topk_best_fitness, k=10, name=\"top10_best_fitness\"),\n",
    "    named_partial(topk_best_fitness, k=100, name=\"top100_best_fitness\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ESM zero-shot performance\n",
    "ESM_ZERO_SHOT = {\n",
    "    name: metric(\n",
    "        y_true=srired.data.query(\"hamming_to_wildtype == 1\")[\"fitness\"].values,\n",
    "        y_pred=srired.data.query(\"hamming_to_wildtype == 1\")[\"esm_log_density\"].values,\n",
    "    )\n",
    "    for name, metric in zip([m.__name__ for m in METRICS], METRICS)\n",
    "}\n",
    "\n",
    "# Set up dataset\n",
    "X = srired.data.query(\"hamming_to_wildtype == 1\")[\"sequence\"].values\n",
    "y = srired.data.query(\"hamming_to_wildtype == 1\")[\"fitness\"].values\n",
    "X_wt = srired.wildtype_seq\n",
    "y_wt = srired.data.query(\"hamming_to_wildtype == 0\")[\"fitness\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Learning curves for the final model (AAIndex Regressor + ESM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_performances = compute_learning_curves(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    model=LookUpPredictor(singles.data.set_index(\"seq\")[\"fitness_esm\"].to_dict(), reg_coef=1e-6),\n",
    "    metrics=METRICS,\n",
    "    sizes=WELL_PLATE_SIZES[:1],\n",
    "    cv=CV,\n",
    "    shuffle_data=True,\n",
    "    random_state=7,\n",
    "    store_predictions=False,\n",
    ")\n",
    "\n",
    "lc_output_lr_w_esm = compute_learning_curves(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    model=JointPredictor(\n",
    "        predictors=[\n",
    "            AAIndexPredictor(reg_coef=1.0, n_components=19, seed=7),\n",
    "            LookUpPredictor(singles.data.set_index(\"seq\")[\"fitness_esm\"].to_dict(), reg_coef=1e-6),\n",
    "        ],\n",
    "        reg_coef=1.0,\n",
    "    ),\n",
    "    metrics=METRICS,\n",
    "    sizes=WELL_PLATE_SIZES,\n",
    "    cv=CV,\n",
    "    shuffle_data=True,\n",
    "    random_state=7,\n",
    "    # X_wt=X_wt,\n",
    "    # y_wt=y_wt,\n",
    "    store_predictions=True,\n",
    ")\n",
    "\n",
    "lc_output_lr = compute_learning_curves(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    model=AAIndexPredictor(reg_coef=1.0, n_components=19, seed=7),\n",
    "    metrics=METRICS,\n",
    "    sizes=WELL_PLATE_SIZES,\n",
    "    cv=CV,\n",
    "    shuffle_data=True,\n",
    "    random_state=7,\n",
    "    # X_wt=X_wt,\n",
    "    # y_wt=y_wt,\n",
    "    store_predictions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True\n",
    "SAVE_DIR = \"./figures/single_mutant_model\"\n",
    "PERCENTAGES = [0.1, 1, 5, 10, 25, 50, 67]\n",
    "WELL_PLATE_SIZES_TICKS = [12, 24, 48, 96, 2 * 96, 384, 2 * 384]\n",
    "\n",
    "for metric in [\"spearman\", \"top10_ndcg\", \"top100_ndcg\", \"top10_precision\"]:\n",
    "    # Extract the data for plotting\n",
    "    keys = []\n",
    "    medians, q25s, q75s = [], [], []\n",
    "    for key, value in lc_output_lr_w_esm[\"result_stats\"].items():\n",
    "        keys.append(int(key))\n",
    "        medians.append(value[metric][\"med\"])\n",
    "        q25s.append(value[metric][\"q25\"])\n",
    "        q75s.append(value[metric][\"q75\"])\n",
    "    keys = np.array(keys)\n",
    "    medians = np.array(medians)\n",
    "    q25s = np.array(q25s)\n",
    "    q75s = np.array(q75s)\n",
    "\n",
    "    if keys[0] == 1:\n",
    "        medians[0] = ESM_ZERO_SHOT[metric]\n",
    "        q25s[0] = ESM_ZERO_SHOT[metric]\n",
    "        q75s[0] = ESM_ZERO_SHOT[metric]\n",
    "\n",
    "    keys_lr_only = []\n",
    "    medians_lr_only, q25s_lr_only, q75s_lr_only = [], [], []\n",
    "    for key, value in lc_output_lr[\"result_stats\"].items():\n",
    "        keys_lr_only.append(int(key))\n",
    "        medians_lr_only.append(value[metric][\"med\"])\n",
    "        q25s_lr_only.append(value[metric][\"q25\"])\n",
    "        q75s_lr_only.append(value[metric][\"q75\"])\n",
    "    keys_lr_only = np.array(keys_lr_only)\n",
    "    medians_lr_only = np.array(medians_lr_only)\n",
    "    q25s_lr_only = np.array(q25s_lr_only)\n",
    "    q75s_lr_only = np.array(q75s_lr_only)\n",
    "\n",
    "    # Plot learning curves\n",
    "    # 1 column figure\n",
    "    with plt.style.context([\"nature\"]):\n",
    "        fig, ax = plt.subplots(figsize=get_dim(width=WIDTH.nature_column))\n",
    "\n",
    "        # Special case for ESM\n",
    "        ax.plot(keys, medians, \"ko-\")\n",
    "        # ax.errorbar(keys, medians, yerr=[medians-q25s, q75s-medians], fmt=\"none\", ecolor=\"k\")\n",
    "        ax.semilogx()\n",
    "        ax.fill_between(keys, q25s, q75s, alpha=0.05, color=\"gray\")\n",
    "        ax.plot(keys, q25s, color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "        ax.plot(keys, q75s, color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "        ax.set_xlabel(\"Training set size\")\n",
    "        # Remove old ticks\n",
    "        ax.set_xticks([], minor=True)\n",
    "        # Set new ticks\n",
    "        ax.set_xticks(WELL_PLATE_SIZES_TICKS, minor=False)\n",
    "        ax.set_xticklabels(WELL_PLATE_SIZES_TICKS, rotation=-00)\n",
    "        ax.set_ylabel(metric.capitalize().replace(\"_\", \" \"))\n",
    "        ax.set_ylim(0, None)\n",
    "        ax.set_xlim(WELL_PLATE_SIZES_TICKS[0], keys[-1])\n",
    "\n",
    "        # Add ESM zero-shot performance on entire dataset\n",
    "        ax.axhline(\n",
    "            ESM_ZERO_SHOT[metric],\n",
    "            color=cambridge_core[0],\n",
    "            linestyle=\"dotted\",\n",
    "            alpha=1,\n",
    "            label=\"ESM-3B PLL fitness (full dataset)\",\n",
    "        )\n",
    "        ax.axhline(\n",
    "            esm_performances[\"result_stats\"][str(WELL_PLATE_SIZES[0])][metric][\"med\"],\n",
    "            color=cambridge_core[3],\n",
    "            linestyle=\"dotted\",\n",
    "            label=\"ESM-3B PLL fitness (on replica)\",\n",
    "        )\n",
    "\n",
    "        # Add LR only\n",
    "        ax.plot(\n",
    "            keys_lr_only,\n",
    "            medians_lr_only,\n",
    "            color=cambridge_core[1],\n",
    "            linestyle=\"dashdot\",\n",
    "            marker=\"^\",\n",
    "            alpha=0.5,\n",
    "            label=\"AAIndex Regressor only\",\n",
    "        )\n",
    "\n",
    "        # Legend\n",
    "        ax.legend(loc=\"best\")\n",
    "\n",
    "        # Show percentage of all singles on secondary x-axis\n",
    "        # Calculate the positions for the secondary axis ticks (10%, 25%, 50% of the primary axis range)\n",
    "        secondary_ticks = np.array(PERCENTAGES) * len(singles) / 100.0\n",
    "\n",
    "        # Duplicate x-axis for % of dataset\n",
    "        ax2 = ax.twiny()\n",
    "        ax2.semilogx()\n",
    "        # Remove old ticks\n",
    "        ax2.set_xticks([], minor=True)\n",
    "        ax2.set_xticks(secondary_ticks, minor=False)\n",
    "        ax2.set_xticklabels([f\"{p}%\" for p in PERCENTAGES])\n",
    "        ax2.set_xlabel(\"Percentage of all singles\")\n",
    "\n",
    "        # Adjust position of secondary x-axis\n",
    "        ax2.xaxis.set_ticks_position(\"bottom\")\n",
    "        ax2.xaxis.set_label_position(\"bottom\")\n",
    "        ax2.spines[\"bottom\"].set_position((\"axes\", -0.28))\n",
    "        ax2.set_xlim(ax.get_xlim())\n",
    "\n",
    "        # Show percentage of all observed data on tertiary x-axis\n",
    "        # Calculate the positions for the secondary axis ticks (10%, 25%, 50% of the primary axis range)\n",
    "        secondary_ticks = np.array(PERCENTAGES) * len(srired.data.query(train)) / 100.0\n",
    "        ax3 = ax.twiny()\n",
    "        ax3.semilogx()\n",
    "        # Remove old ticks\n",
    "        ax3.set_xticks([], minor=True)\n",
    "        ax3.set_xticks(secondary_ticks, minor=False)\n",
    "        ax3.set_xticklabels([f\"{p}%\" for p in PERCENTAGES])\n",
    "        ax3.set_xlabel(\"Percentage of observed singles\")\n",
    "\n",
    "        # Adjust position of secondary x-axis\n",
    "        ax3.xaxis.set_ticks_position(\"bottom\")\n",
    "        ax3.xaxis.set_label_position(\"bottom\")\n",
    "        ax3.spines[\"bottom\"].set_position((\"axes\", -0.56))\n",
    "        ax3.set_xlim(ax.get_xlim())\n",
    "\n",
    "        sns.despine()\n",
    "        plt.title(\"Learning curve - single-mutant fitness prediction\")\n",
    "\n",
    "    if SAVE:\n",
    "        save_timestamped_figure(\n",
    "            f\"learning_curve_singles_{metric}_lr_w_esm_1col\", save_dir=SAVE_DIR, file_types=[\"pdf\"], date_format=\"\"\n",
    "        )\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epzyme2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
